- The document "A Survey on Supervised Classification on Data Streams" describes the difference between incremental learning and online learning. Moreover, it is a good source to look for proposals.
- The paper "RDWM" (Ensemble) explains the different types of concept drift in the introduction. It refers to different approaches for online learning in the introduction too.
- In the additional documents there is a paper about a survey on rough set theory that mentions the probability theory, the fuzzy set theory and the evidence theory.
- http://dsc.soic.indiana.edu/publications/survey_algorithms_streaming.pdf -> Information about some streaming data algorithms
- The paper "Voting Massive Collections of Bayesian Network Classifiers for Data Streams" explains different types of Bayesian classifiers. It compares them referring to the data stream approach.
- There are three basic stream processing models: landmark window model , sliding window model and damped window model [26]. The sliding window considers a fixed number of stream records, compared with landmark window model, 
it detects changes in the properties of stream records faster ( e.g. concept drift), and does not have to assign different weights to stream records (as damped window model).
- In the document "A Survey on Data Stream Clustering and Classification" there is a summary of advantages and limitations of classification algorithms.
- In the paper "Concept drift in Streaming Data Classification: Algorithms, Platforms and Issues" (not in proposals) the concept drift term is explained.
- In the paper "Classifying evolving data streams with partially labeled data (2011)" different types of concept drift are explained (real concept drift and virtual concept drift) and possible sources of
  concept drifts (conditional change, feature change and dual change).
- The paper "Classifying evolving data streams with partially labeled data (2011)" mentions performance indicators over time -> Classification accuracy is the most used indicator, i.e., if there is a consistent drop
  in the accuracy, a drift is signaled. Other performance indicators, such as error rate, recall and precision have also been used.
- The paper "Classifying evolving data streams with partially labeled data (2011)" explains the EM algorithm.
- The paper "Weighted Naïve Bayes Classifier with Forgetting for Drifting Data Streams (2015)" mentions the three main approaches on handling streaming and drifting data.
- The paper "Mining multi-dimensional concept-drifting data streams using Bayesian network classifiers (2016)" mentions different concept drift categorizations.
- The paper "Mining multi-dimensional concept drifting data streams using Bayesian network classifiers (2016)" mentions several change detection methods that have been proposed to determine point at which the concept
  drift occurs. -> As pointed out in [16], these methods can be categorized into four groups: i) methods based on sequential analysis such as the sequential probability ratio test; ii) methods based on control
  charts or statistical process control; iii) methods based on monitoring distributions on two different time-windows such as the ADWIN algorithm; and iv) contextual methods such as the splice system.
  More details about these methods and their references can be found in [16], Section 3.2.
- http://www.otnira.com/2013/03/28/hoeffding-tree-for-streaming-classification/
- The paper "Cost-Sensitive Perceptron Decision Trees for Imbalanced Drifting Data Streams (2017)" contains interesting information for the composition of the TFM (throughout all the paper) -> Mining streaming and drifting data is among the most popular
contemporary applications of machine learning methods; imbalanced data; explanation of different concept drifts (from the point of view of influencing the existing decision boundaries, from the severity of ongoing changes); etcétera.
- The paper "Cost-Sensitive Perceptron Decision Trees for Imbalanced Drifting Data Streams (2017)" mentions the following: In order to tackle the presence of concept drift one may chose among three main approaches:
  (a) rebuilding classifier from a scratch whenever new instances become available; (b) use a specific tool to detect changes and guide the model reconstruction; and  (c) use adaptive classifier that will naturally 
  follow the changes in the stream.  The first approach is completely unsuitable due to prohibitive computational requirements, especially in case of online stream processing. Following the remaining two directions,
  we may distinguish four main approaches to handling drifting data streams. First one relies on using a concept drift detector - an external tool that monitors the characteristics and informs when a change is
  expected to appear. This allows for rebuilding the classifier only when it is deemed as necessary. Second one uses a sliding window in order to keep a track of most recent instances, as they should be most
  representative to the current state of the stream. Such a window follows the stream, discarding old instances and replacing them with most recent ones. However, the size of the window is a crucial factor affecting
  the performance of this approach. Third solution uses online or incremental classifiers that are able to incorporate new instances by updating the classification model without a need for a complete
  retraining. A forgetting mechanism is required in order to allow for better adaptation to changes and reduced model complexity. Finally, ensemble solutions are popularly used for mining drifting data streams.
  Here, new instances may be used to control diversity of the base learners, allowing them to better adapt to changes, while offering improved predictive capabilities.
- The paper "Cost-Sensitive Perceptron Decision Trees for Imbalanced Drifting Data Streams (2017)" The paper "Cost-Sensitive Perceptron Decision Trees for Imbalanced Drifting Data Streams (2017)" explains the
  following: Skewed distributions pose challenges to most of classifiers, as their will lead to a bias towards the majority class, while minority is usually the more important one. This has lead to a number
  of solutions that aims at alleviating this disproportion that can be grouped into three categories: data-level, algorithm-level and hybrid solutions.
- The paper "" mentions that McDiarmid’s inequality is a generalization of the Hoeffding’s inequality, being applicable to both numerical and non-numerical data, as well as better describing the split measures.
- The chapter "Handling numeric attributes in hoeffding trees (2008)" mentions that Gaussian estimator is the least sensitive to hyperparameter value and induced the most accurate models, becoming the default estimator in recent works.
  We could use it to mention proposals that use this type of estimator.
- Survey (3) -> Explains incremental learning and incremental learning on streams (¿online learning?)
- Paper "Online Classification of Nonstationary Data Streams (2002)" -> Methods for extracting patterns from continuous streams of data are known as incremental (online) learning algorithms. The basic idea of
  incremental induction is that upon receiving a new instance, it is much less expensive to update an existing model than to build a new one. On the other hand, as indicated in [6], the incremental algorithms
  suffer from several shortcomings, like high sensitivity to the order of training examples and longer training times than the non-incremental (batch) methods. Pure incremental methods
  consider every new instance, which may be impractical in environments, where transactions arrive at the rate of thousands per second.
- The paper “Incremental Decision Tree based on order statistics (2013)” presents different types of summaries for numerical attributes and mentions things related to summaries for categorical attributes.
- The paper "Data Stream Mining using Decision Tree Learning Algorithms (2014)" mentions the following: A major challenge in data stream classification, which deserves attention but has long assumed that the
  numbers of classes are fixed. However, in data streams, new classes may often appear. For example, a new kind of intrusion may appear in network traffic, or a new category of text may appear in a social text
  stream such as Twitter. When a new class emerges, traditional data stream classifiers misclassify the instances of the new class as one of the old classes. In other words, a traditional classifier is bound to
  misclassify any instance belonging to a new class, because the classifier has not been trained with that class. It is important to be able to proactively detect novel classes in data streams.